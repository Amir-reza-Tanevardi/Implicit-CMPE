# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dh-fLUbJe6OWaPO_ifTcdVacYLzRCXMJ
"""

import os
import sys

sys.path.append("../../")

import pickle
import timeit

import tensorflow_datasets as tfds

import bayesflow as bf
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import tensorflow as tf
from bayesflow.computational_utilities import maximum_mean_discrepancy
from tqdm.autonotebook import tqdm
from train import build_trainer, configurator_blurred

physical_devices = tf.config.list_physical_devices("GPU")
if physical_devices:
    try:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
    except (ValueError, RuntimeError):
        # Invalid device or cannot modify virtual devices once initialized.
        pass

"""# Set up Forward Inference"""

num_test = 500

# 2) Load ImageNette-160 instead of Fashion MNIST
# ------------------------------------------------
def load_imagenette(split, img_size=160):
    ds = tfds.load("imagenette", split=split, as_supervised=True, data_dir = "/work/pi_aghasemi_umass_edu/afzali_umass/W2S/.cache")
    def _prep(image, label):
        image = tf.image.resize(image, [img_size, img_size])
        image = tf.cast(image, tf.float32) / 255.0
        image = image * 2.0 - 1.0
        return image, label   # <<< return the label now
    return (
        ds
        .map(_prep, num_parallel_calls=tf.data.AUTOTUNE)
        .shuffle(1024)
        .prefetch(tf.data.AUTOTUNE)
    )


#train_ds = load_imagenette160("train[:5%]", img_size=160, batch_size=args.batch_size)  # <<< EDITED
val_ds   = load_imagenette("validation", img_size=224)  # <<< EDITED

# <<< ADDED: unbatch then take only num_test examples
test_ds_unbatched = val_ds.take(num_test)
test_imgs = []
test_lbls = []
for img, lbl in test_ds_unbatched:
    test_imgs.append(img.numpy())
    test_lbls.append(lbl.numpy())
test_imgs = np.stack(test_imgs, axis=0)
test_lbls = np.stack(test_lbls, axis=0)

forward_test = {
    "prior_draws": test_imgs,     # shape = (args.num_test, 160,160,3)
    "sim_data":    test_imgs,
}
# Now you also have
test_labels = test_lbls         # shape = (args.num_test,)


"""# Sanity Check"""

# how_many = 5
# conf = configurator_blurred(
#     {
#         "sim_data": forward_train["sim_data"][:how_many],
#         "prior_draws": forward_train["prior_draws"][:how_many],
#     }
# )

# f, axarr = plt.subplots(how_many, 2)
# for i in range(how_many):
#     if i == 0:
#         axarr[i, 0].set_title("Blurred")
#         axarr[i, 1].set_title("True")
#     axarr[i, 0].imshow(
#         conf["summary_conditions"][i, :, :, 0],
#         cmap=plt.cm.get_cmap("Greys"),
#     )
#     axarr[i, 1].imshow(forward_train["prior_draws"][i].reshape(28, 28), cmap=plt.cm.get_cmap("Greys"))
#     axarr[i, 0].axis("off")
#     axarr[i, 1].axis("off")
# f.tight_layout()

"""## Set up Network, Amortizer and Trainer"""

# sampling steps for CMPE - two-step sampling
cmpe_steps = 2
# step size for FMPE, following Flow Matching for Scalable Simulation-Based Inference, https://arxiv.org/pdf/2305.17161.pdf
fmpe_step_size = 1 / 248

def to_id(method, architecture, num_train):
    return f"{method}-{architecture}-{num_train}"

checkpoint_path_dict = {
    to_id("cmpe", "unet", 2000): "checkpoints/cmpe-unet-2000-25-04-03-093413/",
    #to_id("cmpe", "unet", 60000): "checkpoints/cmpe-unet-60000-25-04-10-150038/",
}

arg_dict = {}
for key, checkpoint_path in checkpoint_path_dict.items():
    with open(os.path.join(checkpoint_path, "args.pickle"), "rb") as f:
        arg_dict[key] = pickle.load(f)

trainer_dict = {}
for key, checkpoint_path in checkpoint_path_dict.items():
    trainer_dict[key] = build_trainer(checkpoint_path, arg_dict[key])

for key, trainer in trainer_dict.items():
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    h = trainer.loss_history.get_plottable()
    f = bf.diagnostics.plot_losses(h["train_losses"], h["val_losses"])
    f.savefig(os.path.join(fig_dir, "loss_history.pdf"), bbox_inches="tight", dpi=300)

"""# Evaluation"""

plt.rcParams.update(
    {
        "axes.labelsize": 24,
        "xtick.labelsize": 16,
        "ytick.labelsize": 16,
        "legend.fontsize": 24,
        "text.usetex": False,
        "font.family": "serif",
        "text.latex.preamble": r"\usepackage{{amsmath}}",
    }
)

conf = configurator_blurred(forward_test)

"""## Per-Class Generation: Means and STDs"""

class_names = [
    "tench",            # n01440764
    "English springer", # n02102040
    "cassette player",  # n02979186
    "chain saw",        # n03000684
    "church",           # n03337140
    "French horn",      # n03417042
    "garbage truck",    # n03425413
    "goâ€‘kart",          # n03445777
    "golf ball",        # n03467068
    "parachute",        # n03924679
]

y_labels = [r"Parameter $\theta$", r"Observation $x$", "Mean", "Std.Dev"]

def random_indices_per_class(labels, seed=42):
    out = {}
    unique = np.unique(labels)
    perm = np.random.default_rng(seed).permutation(labels.shape[0])
    for i in unique:
        for idx in perm:
            if i == labels[idx]:
                out[i] = idx
                break
    return out


def create_mean_std_plots(
    trainer, seed=42, filepath=None, n_samples=500, cmpe_steps=30, fmpe_step_size=1 / 248, method=""
):
    """Helper function for displaying Figure 7 in main paper.
    Default seed is the one and only 42!
    """

    idx_dict = random_indices_per_class(test_labels, seed=seed)
    f, axarr = plt.subplots(4, len(idx_dict), figsize=(12, 4))
    for i, (c, idx) in tqdm(enumerate(idx_dict.items()), total=len(idx_dict)):
        # print(f"{i+1:02}/{len(class_names)}", end="\r")
        # Prepare input dict for network
        inp = {
            "parameters": conf["parameters"][idx : (idx + 1)],
            "summary_conditions": conf["summary_conditions"][idx : (idx + 1)],
        }

        # Obtain samples and clip to prior range, instead of rejecting
        if method == "cmpe":
            samples = trainer.amortizer.sample(inp, n_steps=cmpe_steps, n_samples=n_samples)
        else:
            samples = trainer.amortizer.sample(inp, n_samples=n_samples, step_size=fmpe_step_size)
        samples = np.clip(samples, a_min=-1.01, a_max=1.01)

        # Plot truth and blurred
        axarr[0,i].imshow((inp["parameters"].reshape(224,224,3)+1)/2)
        axarr[1,i].imshow((inp["summary_conditions"].reshape(224,224,3)+1)/2)
        axarr[2,i].imshow((samples.mean(0).reshape(224,224,3)+1)/2)
        axarr[3,i].imshow((samples.std(0).reshape(224,224,3)+1)/2)
        axarr[0, i].set_title(class_names[i])

    for j, label in enumerate(y_labels):
        axarr[j, 0].set_ylabel(label, rotation=0, labelpad=55, fontsize=12)

    # get rid of axis
    for ax in axarr.flat:
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)
        ax.spines["top"].set_visible(False)
        ax.spines["bottom"].set_visible(False)
        ax.set_yticklabels([])
        ax.set_yticks([])
        ax.set_xticklabels([])
        ax.set_xticks([])
    f.tight_layout()

    if filepath is not None:
        f.savefig(filepath, dpi=300, bbox_inches="tight")
    return f

for key, trainer in trainer_dict.items():
    print(key)
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    f = create_mean_std_plots(
        trainer,
        seed=42,
        filepath=os.path.join(fig_dir, "main.pdf"),
        method=arg_dict[key].method,
        cmpe_steps=cmpe_steps,
        fmpe_step_size=fmpe_step_size,
    )

"""## Per-Class Generation: Samples"""

def create_sample_plots(trainer, seed=42, filepath=None, cmpe_steps=30, fmpe_step_size=1 / 248, method=""):
    """Helper function for displaying Figure 7 in main paper.
    Default seed is the one and only 42!
    """

    idx_dict = random_indices_per_class(test_labels, seed=seed)
    n_samples = 5
    f, axarr = plt.subplots(len(idx_dict), 2 + n_samples, figsize=(8.27, 11.69))
    titles = [r"Param. $\theta$", r"Obs. $x$"] + n_samples * ["Sample"]
    for i, (c, idx) in tqdm(enumerate(idx_dict.items()), total=len(idx_dict)):
        # Prepare input dict for network
        inp = {
            "parameters": conf["parameters"][idx : (idx + 1)],
            "summary_conditions": conf["summary_conditions"][idx : (idx + 1)],
        }

        # Obtain samples and clip to prior range, instead of rejecting
        if method == "cmpe":
            samples = trainer.amortizer.sample(inp, n_steps=cmpe_steps, n_samples=n_samples)
        else:
            samples = trainer.amortizer.sample(inp, n_samples=n_samples, step_size=fmpe_step_size)
        samples = np.clip(samples, a_min=-1.01, a_max=1.01)

        # Plot truth and blurred
        axarr[0,i].imshow((inp["parameters"].reshape(224,224,3)+1)/2)
        axarr[1,i].imshow((inp["summary_conditions"].reshape(224,224,3)+1)/2)
        axarr[2,i].imshow((samples.mean(0).reshape(224,224,3)+1)/2)
        for j in range(n_samples):
            axarr[i, 2 + j].imshow((samples[j].reshape(224,224,3)+1)/2)

        axarr[i, 0].set_ylabel(class_names[i], fontsize=12)

    for i, title in enumerate(titles):
        axarr[0, i].set_title(title, fontsize=12)

    # get rid of axis
    for ax in axarr.flat:
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)
        ax.spines["top"].set_visible(False)
        ax.spines["bottom"].set_visible(False)
        ax.set_yticklabels([])
        ax.set_yticks([])
        ax.set_xticklabels([])
        ax.set_xticks([])
    f.tight_layout()

    if filepath is not None:
        f.savefig(filepath, dpi=300, bbox_inches="tight")
        pass
    return f

for key, trainer in trainer_dict.items():
    print(key)
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    f = create_sample_plots(
        trainer,
        seed=42,
        filepath=os.path.join(fig_dir, "samples_main.pdf"),
        method=arg_dict[key].method,
        cmpe_steps=cmpe_steps,
        fmpe_step_size=fmpe_step_size,
    )
    f.show()


##############################
### New Metrics
##############################

from skimage.metrics import peak_signal_noise_ratio, structural_similarity, mean_squared_error
import torchvision.transforms.functional as TF
import torch
import lpips
import numpy as np
import os
import timeit
import torch.nn.functional as F
from torchmetrics.image.kid import KernelInceptionDistance

# Initialize LPIPS metric
lpips_metric = lpips.LPIPS(net='alex')  # Pretrained LPIPS model

# Initialize KID metric
kid_metric = KernelInceptionDistance(subset_size=50)

all_psnr = []
all_ssim = []
all_lpips = []
all_mses = []

n_samples = 1
n_datasets = 500

# <<< EDITED FOR IMAGENETTE: parameters are 160*160*3 vectors now
parameters = conf["parameters"][:n_datasets]  # shape (n, 160*160*3)

def render_from_params(param_vector):
    """
    Reshape a flattened parameter vector into a (160, 160, 3) RGB image.
    Assumes input is a 1D array of shape (160*160*3,).
    """
    img = param_vector.reshape(224, 224, 3)     # <<< EDITED
    # scale from [-1,1] back to [0,1]
    return (img + 1.0) / 2.0                    # <<< EDITED

for key, trainer in trainer_dict.items():
    print(key, end="")

    # sample once, to avoid contaminating timing with tracing
    c = conf["summary_conditions"][0, None]
    print(f" Initializing...")
    if arg_dict[key].method == "cmpe":
        trainer.amortizer.sample({"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples)
    
    for theta in np.linspace(3,3,1):
        # store samples
        post_samples = np.zeros((n_datasets, n_samples, parameters.shape[-1]))  # <<< EDITED

        tic = timeit.default_timer()
        for i in range(n_datasets):
            print(f"{i+1:03}/{n_datasets}", end="\r")
            c = conf["summary_conditions"][i, None]
            if arg_dict[key].method == "cmpe":
                post_samples[i] = trainer.amortizer.sample(
                    {"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples
                )

            # Ground truth
            true_param = parameters[i]
            true_img = render_from_params(true_param)     # (160, 160, 3), [0,1]   # <<< EDITED
            true_tensor = TF.to_tensor(true_img).unsqueeze(0)              # shape (1,3,160,160)  # <<< EDITED
            # KID/Inception expects 299Ã—299 uint8
            true_tensor_299 = F.interpolate(
                (true_tensor * 255.0).clamp(0,255).to(torch.uint8),
                size=(299, 299),
                mode='bilinear',
                align_corners=False
            )

            # Accumulate metrics across samples
            sample_psnr = []
            sample_ssim = []
            sample_lpips = []
            sample_mse = []

            for j in range(n_samples):
                recon_img = render_from_params(post_samples[i, j])  # <<< EDITED
                recon_tensor = TF.to_tensor(recon_img).unsqueeze(0) # <<< EDITED
                recon_tensor_299 = F.interpolate(
                    (recon_tensor * 255.0).clamp(0,255).to(torch.uint8),
                    size=(299, 299),
                    mode='bilinear',
                    align_corners=False
                )

                # Add to KID (distribution-level comparison)
                kid_metric.update(true_tensor_299, real=True)
                kid_metric.update(recon_tensor_299, real=False)

                # Image-level metrics on [0,1]
                psnr = peak_signal_noise_ratio(true_img, recon_img, data_range=1.0)
                ssim = structural_similarity(true_img, recon_img, channel_axis=-1, data_range=1.0)
                mse  = mean_squared_error(true_img, recon_img)

                # LPIPS on 64Ã—64 float in [-1,1]
                img1_lpips = F.interpolate((recon_tensor*2-1), size=(64, 64), mode='bilinear', align_corners=False).float()  # <<< EDITED
                img2_lpips = F.interpolate((true_tensor*2-1), size=(64, 64), mode='bilinear', align_corners=False).float()  # <<< EDITED
                lp = lpips_metric(img1_lpips, img2_lpips).item()

                sample_psnr.append(psnr)
                sample_ssim.append(ssim)
                sample_lpips.append(lp)
                sample_mse.append(mse)

            # Average over all posterior samples for this dataset
            all_psnr.append(np.mean(sample_psnr))
            all_ssim.append(np.mean(sample_ssim))
            all_lpips.append(np.mean(sample_lpips))
            all_mses.append(np.mean(sample_mse))

        toc = timeit.default_timer()
        duration = toc - tic

        # Final KID score
        kid_mean, kid_std = kid_metric.compute()

        print(
            f"Theta: {theta:.3f}  "
            f"PSNR: {np.mean(all_psnr):.2f} dB, "
            f"SSIM: {np.mean(all_ssim):.3f}, "
            f"LPIPS: {np.mean(all_lpips):.3f}, "
            f"MSE: {np.mean(all_mses):.3f}, "
            f"KID: {kid_mean.item():.4f}Â±{kid_std.item():.4f}"
        )
