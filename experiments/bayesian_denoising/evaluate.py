# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dh-fLUbJe6OWaPO_ifTcdVacYLzRCXMJ
"""

import os
import sys

sys.path.append("../../")

import pickle
import timeit

import bayesflow as bf
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import tensorflow as tf
from bayesflow.computational_utilities import maximum_mean_discrepancy
from tqdm.autonotebook import tqdm
from train import build_trainer, configurator, configurator_masked

physical_devices = tf.config.list_physical_devices("GPU")
if physical_devices:
    try:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
    except (ValueError, RuntimeError):
        # Invalid device or cannot modify virtual devices once initialized.
        pass

"""# Set up Forward Inference"""

fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()

forward_train = {"prior_draws": train_images, "sim_data": train_images}

num_val = 500
perm = np.random.default_rng(seed=42).permutation(test_images.shape[0])

forward_val = {
    "prior_draws": test_images[perm[:num_val]],
    "sim_data": test_images[perm[:num_val]],
}

forward_test = {
    "prior_draws": test_images[perm[num_val:]],
    "sim_data": test_images[perm[num_val:]],
}

val_labels = test_labels[perm[:num_val]]
test_labels = test_labels[perm[num_val:]]

"""# Sanity Check"""

how_many = 5
conf = configurator(
    {
        "sim_data": forward_train["sim_data"][:how_many],
        "prior_draws": forward_train["prior_draws"][:how_many],
    }
)

f, axarr = plt.subplots(how_many, 2)
for i in range(how_many):
    if i == 0:
        axarr[i, 0].set_title("Blurred")
        axarr[i, 1].set_title("True")
    axarr[i, 0].imshow(
        conf["summary_conditions"][i, :, :, 0],
        cmap=plt.cm.get_cmap("Greys"),
    )
    axarr[i, 1].imshow(forward_train["prior_draws"][i].reshape(28, 28), cmap=plt.cm.get_cmap("Greys"))
    axarr[i, 0].axis("off")
    axarr[i, 1].axis("off")
f.tight_layout()

"""## Set up Network, Amortizer and Trainer"""

# sampling steps for CMPE - two-step sampling
cmpe_steps = 2
# step size for FMPE, following Flow Matching for Scalable Simulation-Based Inference, https://arxiv.org/pdf/2305.17161.pdf
fmpe_step_size = 1 / 248

def to_id(method, architecture, num_train):
    return f"{method}-{architecture}-{num_train}"

checkpoint_path_dict = {
    to_id("cmpe", "unet", 2000): "checkpoints/cmpe-unet-2000-25-04-03-093413/",
    #to_id("cmpe", "unet", 2000): "checkpoints/cmpe-unet-2000-25-16-04-099999/",
    #to_id("cmpe", "unet", 60000): "checkpoints/cmpe-unet-60000-25-04-10-150038/",
}

arg_dict = {}
for key, checkpoint_path in checkpoint_path_dict.items():
    with open(os.path.join(checkpoint_path, "args.pickle"), "rb") as f:
        arg_dict[key] = pickle.load(f)

trainer_dict = {}
for key, checkpoint_path in checkpoint_path_dict.items():
    trainer_dict[key] = build_trainer(checkpoint_path, arg_dict[key])

for key, trainer in trainer_dict.items():
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    h = trainer.loss_history.get_plottable()
    f = bf.diagnostics.plot_losses(h["train_losses"], h["val_losses"])
    f.savefig(os.path.join(fig_dir, "loss_history.pdf"), bbox_inches="tight", dpi=300)

"""# Evaluation"""

plt.rcParams.update(
    {
        "axes.labelsize": 24,
        "xtick.labelsize": 16,
        "ytick.labelsize": 16,
        "legend.fontsize": 24,
        "text.usetex": False,
        "font.family": "serif",
        "text.latex.preamble": r"\usepackage{{amsmath}}",
    }
)

conf = configurator(forward_test)

"""## Per-Class Generation: Means and STDs"""

class_names = [
    "T-Shirt/Top",
    "Trouser",
    "Pullover",
    "Dress",
    "Coat",
    "Sandal",
    "Shirt",
    "Sneaker",
    "Bag",
    "Ankle Boot",
]

y_labels = [r"Parameter $\theta$", r"Observation $x$", "Mean", "Std.Dev"]

def random_indices_per_class(labels, seed=42):
    out = {}
    unique = np.unique(labels)
    perm = np.random.default_rng(seed).permutation(labels.shape[0])
    for i in unique:
        for idx in perm:
            if i == labels[idx]:
                out[i] = idx
                break
    return out


# def create_mean_std_plots(
#     trainer, seed=42, filepath=None, n_samples=500, cmpe_steps=30, fmpe_step_size=1 / 248, method=""
# ):
#     """Helper function for displaying Figure 7 in main paper.
#     Default seed is the one and only 42!
#     """

#     idx_dict = random_indices_per_class(test_labels, seed=seed)
#     f, axarr = plt.subplots(4, len(idx_dict), figsize=(12, 4))
#     for i, (c, idx) in tqdm(enumerate(idx_dict.items()), total=len(idx_dict)):
#         # print(f"{i+1:02}/{len(class_names)}", end="\r")
#         # Prepare input dict for network
#         inp = {
#             "parameters": conf["parameters"][idx : (idx + 1)],
#             "summary_conditions": conf["summary_conditions"][idx : (idx + 1)],
#         }

#         # Obtain samples and clip to prior range, instead of rejecting
#         if method == "cmpe":
#             samples = trainer.amortizer.sample(inp, n_steps=cmpe_steps, n_samples=n_samples)
#         else:
#             samples = trainer.amortizer.sample(inp, n_samples=n_samples, step_size=fmpe_step_size)
#         samples = np.clip(samples, a_min=-1.01, a_max=1.01)

#         # Plot truth and blurred
#         axarr[0, i].imshow(inp["parameters"].reshape((28, 28, 1)), cmap=matplotlib.colormaps["binary"])
#         axarr[1, i].imshow(
#             inp["summary_conditions"].reshape((28, 28, 1)),
#             cmap=matplotlib.colormaps["binary"],
#         )
#         axarr[2, i].imshow(samples.mean(0).reshape(28, 28, 1), cmap=matplotlib.colormaps["binary"])
#         axarr[3, i].imshow(samples.std(0).reshape(28, 28, 1), cmap=matplotlib.colormaps["binary"])

#         axarr[0, i].set_title(class_names[i])

#     for j, label in enumerate(y_labels):
#         axarr[j, 0].set_ylabel(label, rotation=0, labelpad=55, fontsize=12)

#     # get rid of axis
#     for ax in axarr.flat:
#         ax.spines["right"].set_visible(False)
#         ax.spines["left"].set_visible(False)
#         ax.spines["top"].set_visible(False)
#         ax.spines["bottom"].set_visible(False)
#         ax.set_yticklabels([])
#         ax.set_yticks([])
#         ax.set_xticklabels([])
#         ax.set_xticks([])
#     f.tight_layout()

#     if filepath is not None:
#         f.savefig(filepath, dpi=300, bbox_inches="tight")
#     return f

# for key, trainer in trainer_dict.items():
#     print(key)
#     fig_dir = f"figures/{key}"
#     os.makedirs(fig_dir, exist_ok=True)
#     f = create_mean_std_plots(
#         trainer,
#         seed=42,
#         filepath=os.path.join(fig_dir, "main.pdf"),
#         method=arg_dict[key].method,
#         cmpe_steps=cmpe_steps,
#         fmpe_step_size=fmpe_step_size,
#     )

"""## Per-Class Generation: Samples"""

def create_sample_plots(trainer, seed=42, filepath=None, cmpe_steps=30, fmpe_step_size=1 / 248, method=""):
    """Helper function for displaying Figure 7 in main paper.
    Default seed is the one and only 42!
    """

    idx_dict = random_indices_per_class(test_labels, seed=seed)
    n_samples = 5
    f, axarr = plt.subplots(len(idx_dict), 2 + n_samples, figsize=(8.27, 11.69))
    titles = [r"Param. $\theta$", r"Obs. $x$"] + n_samples * ["Sample"]
    for i, (c, idx) in tqdm(enumerate(idx_dict.items()), total=len(idx_dict)):
        # Prepare input dict for network
        inp = {
            "parameters": conf["parameters"][idx : (idx + 1)],
            "summary_conditions": conf["summary_conditions"][idx : (idx + 1)],
        }

        # Obtain samples and clip to prior range, instead of rejecting
        if method == "cmpe":
            samples = trainer.amortizer.sample_addim(inp, n_steps=cmpe_steps, n_samples=n_samples)
        else:
            samples = trainer.amortizer.sample(inp, n_samples=n_samples, step_size=fmpe_step_size)
        samples = np.clip(samples, a_min=-1.01, a_max=1.01)

        # Plot truth and blurred
        axarr[i, 0].imshow(inp["parameters"].reshape((28, 28, 1)), cmap=matplotlib.colormaps["binary"])
        axarr[i, 1].imshow(
            inp["summary_conditions"].reshape((28, 28, 1)),
            cmap=matplotlib.colormaps["binary"],
        )
        for j in range(n_samples):
            axarr[i, 2 + j].imshow(samples[j].reshape(28, 28, 1), cmap=matplotlib.colormaps["binary"])

        axarr[i, 0].set_ylabel(class_names[i], fontsize=12)

    for i, title in enumerate(titles):
        axarr[0, i].set_title(title, fontsize=12)

    # get rid of axis
    for ax in axarr.flat:
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)
        ax.spines["top"].set_visible(False)
        ax.spines["bottom"].set_visible(False)
        ax.set_yticklabels([])
        ax.set_yticks([])
        ax.set_xticklabels([])
        ax.set_xticks([])
    f.tight_layout()

    if filepath is not None:
        f.savefig(filepath, dpi=300, bbox_inches="tight")
        pass
    return f

for key, trainer in trainer_dict.items():
    print(key)
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    f = create_sample_plots(
        trainer,
        seed=42,
        filepath=os.path.join(fig_dir, "samples_main.pdf"),
        method=arg_dict[key].method,
        cmpe_steps=cmpe_steps,
        fmpe_step_size=fmpe_step_size,
    )
    f.show()

# """### Averaged RMSE"""

# n_samples = 100
# n_datasets = 100
# parameters = conf["parameters"][:n_datasets]

# for key, trainer in trainer_dict.items():
#     print(key, end="")

#     # sample once, to avoid contaminating timing with tracing
#     c = conf["summary_conditions"][0, None]
#     print(f" Initializing...")
#     if arg_dict[key].method == "cmpe":
#         trainer.amortizer.sample_implicit({"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples)
#     else:
#         trainer.amortizer.sample({"summary_conditions": c}, n_samples=n_samples, step_size=fmpe_step_size)

#     # store samples
#     post_samples = np.zeros((n_datasets, n_samples, conf["parameters"].shape[-1]))

#     tic = timeit.default_timer()
#     for i in range(n_datasets):
#         print(f"{i+1:03}/{n_datasets}", end="\r")
#         c = conf["summary_conditions"][i, None]
#         if arg_dict[key].method == "cmpe":
#             post_samples[i] = trainer.amortizer.sample_implicit(
#                 {"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples
#             )
#         else:
#             post_samples[i] = trainer.amortizer.sample(
#                 {"summary_conditions": c}, n_samples=n_samples, step_size=fmpe_step_size
#             )
#     toc = timeit.default_timer()

#     duration = toc - tic
#     rmse = bf.computational_utilities.aggregated_rmse(parameters, post_samples)

#     output_dir = f"evaluation/{key}"
#     os.makedirs(output_dir, exist_ok=True)
#     with open(os.path.join(output_dir, "rmse.csv"), "w") as f:
#         f.write(f"duration,rmse\n{duration},{float(rmse)}\n")
#     np.save(os.path.join(output_dir, "rmse_samples.npy"), post_samples)
#     print(f"duration: {duration/(n_datasets * n_samples) * 1000:.2f}ms\nRMSE:{float(rmse):.3f}")

# """RMSE for predicting only zeros:"""

# bf.computational_utilities.aggregated_rmse(parameters, tf.zeros_like(conf["summary_conditions"][:n_datasets, None]))

# """RMSE for predicting the noisy image:"""

# bf.computational_utilities.aggregated_rmse(parameters, conf["summary_conditions"][:n_datasets, None])

# """### MMD

# Split the training images into six parts (due to memory limits) and calculate the maximum mean discrepancy.
# """

# import tensorflow as tf

# def maximum_mean_discrepancy1(x, y, sigma=1.0):
#     """
#     Computes Maximum Mean Discrepancy (MMD) using an RBF kernel.
#     Inputs must be tf.float32.
#     """

#     x = tf.cast(x, tf.float32)
#     y = tf.cast(y, tf.float32)

#     def rbf_kernel(a, b, sigma):
#         norm_a = tf.reduce_sum(tf.square(a), axis=1, keepdims=True)
#         norm_b = tf.reduce_sum(tf.square(b), axis=1, keepdims=True)
#         dists = norm_a - 2 * tf.matmul(a, b, transpose_b=True) + tf.transpose(norm_b)
#         return tf.exp(-dists / (2.0 * sigma ** 2))

#     #x = tf.squeeze(x, axis=1)
#     #y = tf.squeeze(y, axis=1) 
#     K_xx = rbf_kernel(x, x, sigma)
#     K_yy = rbf_kernel(y, y, sigma)
#     K_xy = rbf_kernel(x, y, sigma)

#     n = tf.cast(tf.shape(x)[0], tf.float32)

#     mmd = tf.reduce_sum(K_xx) / (n * n) + tf.reduce_sum(K_yy) / (n * n) - 2 * tf.reduce_sum(K_xy) / (n * n)
#     return mmd


# n = 9000
# parameters = conf["parameters"][:n, None]
# #c  = conf["summary_conditions"][:100, None]
# split_size = 100

# p_samples = np.zeros((n , 1,conf["parameters"].shape[-1]))

# for key, trainer in trainer_dict.items():
#     print(f'key: {key}')

#     if arg_dict[key].method == "cmpe":
#       for i in range(n):
#         #print("Here")
#         c  = conf["summary_conditions"][i, None]
#         p_samples[i] = trainer.amortizer.sample_implicit({"summary_conditions": c}, n_steps=cmpe_steps, n_samples=1, to_numpy=False)
#     # else: 
#     #    samples = trainer.amortizer.sample(conf, n_samples=1, step_size=fmpe_step_size, to_numpy=False)
#     mmds = np.zeros((90,))
#     for i in range(90):
#         # print(i)
#         # print(f'p_sampels.shape: {p_samples.shape}')
#         # print(f'parameters.shape: {parameters.shape}')
#         x = parameters[(i * split_size) : ((i + 1) * split_size)]
#         y = p_samples[(i * split_size) : ((i + 1) * split_size), 0]

#         x = tf.reshape(x, [split_size, -1])
#         y = tf.reshape(y, [split_size, -1])

#         mmds[i] = maximum_mean_discrepancy1(x, y)

#     output_dir = f"evaluation/{key}"
#     os.makedirs(output_dir, exist_ok=True)
#     np.save(os.path.join(output_dir, "mmds.npy"), mmds)
#     print(f"{mmds.mean():.5f}, std: {mmds.std():.5f}")



##############################
### New Metrics
##############################


from skimage.metrics import peak_signal_noise_ratio, structural_similarity, mean_squared_error
import torchvision.transforms.functional as TF
import torch
import lpips
import numpy as np
import os
import timeit
import torch.nn.functional as F
from torchmetrics.image.kid import KernelInceptionDistance

# Initialize LPIPS metric
lpips_metric = lpips.LPIPS(net='alex')  # Pretrained LPIPS model

# Initialize KID metric
kid_metric = KernelInceptionDistance(subset_size=50)

all_psnr = []
all_ssim = []
all_lpips = []
all_mses = []

n_samples = 1
n_datasets = 1000
parameters = conf["parameters"][:n_datasets]

def render_from_params(param_vector):
    """
    Reshape a flattened parameter vector into a (28, 28) image.
    Assumes input is a 1D array of shape (784,).
    """
    return param_vector.reshape(28, 28)

for key, trainer in trainer_dict.items():
    print(key, end="")

    # sample once, to avoid contaminating timing with tracing
    c = conf["summary_conditions"][0, None]
    print(f" Initializing...")
    if arg_dict[key].method == "cmpe":
        trainer.amortizer.sample_addim({"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples)
    
    for theta in np.linspace(3,3,1):
        # store samples
        post_samples = np.zeros((n_datasets, n_samples, conf["parameters"].shape[-1]))

        tic = timeit.default_timer()
        for i in range(n_datasets):
            print(f"{i+1:03}/{n_datasets}", end="\r")
            c = conf["summary_conditions"][i, None]
            if arg_dict[key].method == "cmpe":
                post_samples[i] = trainer.amortizer.sample_addim(
                    {"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples#, theta=theta
                )

            # Ground truth
            true_param = parameters[i]
            true_img = render_from_params(true_param)  # (28, 28)
            true_tensor = TF.to_tensor(true_img).repeat(3, 1, 1).unsqueeze(0) * 2 - 1
            true_tensor_299 = F.interpolate(
                ((true_tensor + 1) * 127.5).clamp(0, 255), size=(299, 299), mode='bilinear', align_corners=False
            ).to(torch.uint8)



            # Accumulate metrics across samples
            sample_psnr = []
            sample_ssim = []
            sample_lpips = []
            sample_mse = []

            for j in range(n_samples):
                recon_img = render_from_params(post_samples[i, j])
                recon_tensor = TF.to_tensor(recon_img).repeat(3, 1, 1).unsqueeze(0) * 2 - 1
                recon_tensor_299 = F.interpolate(
                    ((recon_tensor + 1) * 127.5).clamp(0, 255), size=(299, 299), mode='bilinear', align_corners=False
                ).to(torch.uint8)
                # Add to KID (distribution-level comparison)
                kid_metric.update(true_tensor_299, real=True)
                kid_metric.update(recon_tensor_299, real=False)

                # Image-level metrics
                psnr = peak_signal_noise_ratio(true_img, recon_img, data_range=1.0)
                ssim = structural_similarity(true_img, recon_img, data_range=1.0)
                mse = mean_squared_error(true_img, recon_img)

                img1_lpips = F.interpolate(recon_tensor, size=(64, 64), mode='bilinear', align_corners=False).float()
                img2_lpips = F.interpolate(true_tensor, size=(64, 64), mode='bilinear', align_corners=False).float()
                lp = lpips_metric(img1_lpips, img2_lpips).item()

                sample_psnr.append(psnr)
                sample_ssim.append(ssim)
                sample_lpips.append(lp)
                sample_mse.append(mse)

            # Average over all posterior samples for this dataset
            all_psnr.append(np.mean(sample_psnr))
            all_ssim.append(np.mean(sample_ssim))
            all_lpips.append(np.mean(sample_lpips))
            all_mses.append(np.mean(sample_mse))

        toc = timeit.default_timer()
        duration = toc - tic

        # Final KID score
        kid_mean, kid_std = kid_metric.compute()

        print(f"Theta: {theta:.3f}"
              f"Avg PSNR: {np.mean(all_psnr):.2f}dB, "
              f"SSIM: {np.mean(all_ssim):.3f}, "
              f"LPIPS: {np.mean(all_lpips):.3f}, "
              f"MSE: {np.mean(all_mses):.3f}, "
              f"KID: {kid_mean.item():.4f} Â± {kid_std.item():.4f}")
