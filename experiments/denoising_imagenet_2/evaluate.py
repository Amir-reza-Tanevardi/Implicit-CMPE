# -*- coding: utf-8 -*-
"""evaluate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dh-fLUbJe6OWaPO_ifTcdVacYLzRCXMJ
"""

import os
import sys

sys.path.append("../../")

import pickle
import timeit
import argparse

import tensorflow_datasets as tfds
from argparse import Namespace


import bayesflow as bf
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import tensorflow as tf
from bayesflow.computational_utilities import maximum_mean_discrepancy
from tqdm.autonotebook import tqdm
from train import build_trainer, configurator_blurred

physical_devices = tf.config.list_physical_devices("GPU")
if physical_devices:
    try:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
    except (ValueError, RuntimeError):
        # Invalid device or cannot modify virtual devices once initialized.
        pass

"""# Set up Forward Inference"""



parser = argparse.ArgumentParser(description="Evaluation script with arguments.")

parser.add_argument('--c1', type=float, default=1.0, help='First coefficient (float).')
parser.add_argument('--c2', type=float, default=1.0, help='Second coefficient (float).')
parser.add_argument('--num_test', type=int, default=1000, help='Second coefficient (float).')
parser.add_argument('--type', type=str, default='default', choices=['default', 'addim'],
                    help='Evaluation type: default, or addim.')
parser.add_argument('--path', type=str, default='checkpoints/imagenet-unet-deblurring-2/',
                    help='ckpt path.')

args = parser.parse_args()

num_test = args.num_test
img_size=224

# 2) Load ImageNette-160 instead of Fashion MNIST
# ------------------------------------------------
# def load_imagenette160(split, img_size=160):
#     ds = tfds.load("imagenette/160px", split=split, as_supervised=True)
#     def _prep(image, label):
#         image = tf.image.resize(image, [img_size, img_size])
#         image = tf.cast(image, tf.float32) / 255.0
#         image = image * 2.0 - 1.0
#         return image, label   # <<< return the label now
#     return (
#         ds
#         .map(_prep, num_parallel_calls=tf.data.AUTOTUNE)
#         .shuffle(1024)
#         .prefetch(tf.data.AUTOTUNE)
#     )

def load_imagenet(img_size, split):
    """Loads ImageNet using TensorFlow Datasets."""
    import tensorflow_datasets as tfds
    def _preprocess(image, label):
        image = tf.image.resize(image, [img_size, img_size])
        image = tf.cast(image, tf.float32) / 255.0  # [0,1]
        image = image * 2.0 - 1.0  # [-1,1]
        return image, label

    ds = tfds.load('imagenette', split=split, as_supervised=True, data_dir = "/work/pi_aghasemi_umass_edu/afzali_umass/W2S/.cache")
    ds = ds.map(_preprocess, num_parallel_calls=tf.data.AUTOTUNE)
    #ds = ds.shuffle(1024).prefetch(tf.data.AUTOTUNE)
    return ds


#train_ds = load_imagenette160("train[:5%]", img_size=160, batch_size=args.batch_size)  # <<< EDITED
test_ds = load_imagenet(img_size, 'validation')  # <<< EDITED

# <<< ADDED: unbatch then take only num_test examples
test_ds_unbatched = test_ds.take(num_test)
test_imgs = []
test_lbls = []
for img, lbl in test_ds_unbatched:
    test_imgs.append(img.numpy())
    test_lbls.append(lbl.numpy())
test_imgs = np.stack(test_imgs, axis=0)
test_lbls = np.stack(test_lbls, axis=0)

forward_test = {
    "prior_draws": test_imgs,     # shape = (args.num_test, 160,160,3)
    "sim_data":    test_imgs,
}
# Now you also have
test_labels = test_lbls         # shape = (args.num_test,)


"""# Sanity Check"""

# how_many = 5
# conf = configurator_blurred(
#     {
#         "sim_data": forward_train["sim_data"][:how_many],
#         "prior_draws": forward_train["prior_draws"][:how_many],
#     }
# )

# f, axarr = plt.subplots(how_many, 2)
# for i in range(how_many):
#     if i == 0:
#         axarr[i, 0].set_title("Blurred")
#         axarr[i, 1].set_title("True")
#     axarr[i, 0].imshow(
#         conf["summary_conditions"][i, :, :, 0],
#         cmap=plt.cm.get_cmap("Greys"),
#     )
#     axarr[i, 1].imshow(forward_train["prior_draws"][i].reshape(28, 28), cmap=plt.cm.get_cmap("Greys"))
#     axarr[i, 0].axis("off")
#     axarr[i, 1].axis("off")
# f.tight_layout()

"""## Set up Network, Amortizer and Trainer"""

# sampling steps for CMPE - two-step sampling
cmpe_steps = 2
# step size for FMPE, following Flow Matching for Scalable Simulation-Based Inference, https://arxiv.org/pdf/2305.17161.pdf
fmpe_step_size = 1 / 248

def to_id(method, architecture, num_train):
    return f"{method}-{architecture}-{num_train}"

checkpoint_path_dict = {
    to_id("cmpe", "unet", 12000): args.path,
    #to_id("cmpe", "unet", 60000): "checkpoints/cmpe-unet-60000-25-04-10-150038/",
}

arg_dict = {}
for key, checkpoint_path in checkpoint_path_dict.items():
    with open(os.path.join(checkpoint_path, "args.pkl"), "rb") as f:
        #arg_dict[key] = Namespace(**pickle.load(f))
        arg_dict[key] = pickle.load(f)

trainer_dict = {}
for key, checkpoint_path in checkpoint_path_dict.items():
    trainer_dict[key] = build_trainer(checkpoint_path, arg_dict[key])

for key, trainer in trainer_dict.items():
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    h = trainer.loss_history.get_plottable()
    f = bf.diagnostics.plot_losses(h["train_losses"], h["val_losses"])
    f.savefig(os.path.join(fig_dir, "loss_history.pdf"), bbox_inches="tight", dpi=300)

"""# Evaluation"""

plt.rcParams.update(
    {
        "axes.labelsize": 24,
        "xtick.labelsize": 16,
        "ytick.labelsize": 16,
        "legend.fontsize": 24,
        "text.usetex": False,
        "font.family": "serif",
        "text.latex.preamble": r"\usepackage{{amsmath}}",
    }
)

conf = configurator_blurred(forward_test)

"""## Per-Class Generation: Means and STDs"""

class_names = [
    "tench",            # n01440764
    "English springer", # n02102040
    "cassette player",  # n02979186
    "chain saw",        # n03000684
    "church",           # n03337140
    "French horn",      # n03417042
    "garbage truck",    # n03425413
    "go‑kart",          # n03445777
    "golf ball",        # n03467068
    "parachute",        # n03924679
]

y_labels = [r"Parameter $\theta$", r"Observation $x$", "Mean", "Std.Dev"]

def random_indices_per_class(labels, seed=42):
    out = {}
    unique = np.unique(labels)
    perm = np.random.default_rng(seed).permutation(labels.shape[0])
    for i in unique:
        for idx in perm:
            if i == labels[idx]:
                out[i] = idx
                break
    return out


def create_mean_std_plots(
    trainer, seed=42, filepath=None, n_samples=500, cmpe_steps=30, fmpe_step_size=1 / 248, method="" , image_size=224
):
    """Helper function for displaying Figure 7 in main paper.
    Default seed is the one and only 42!
    """

    idx_dict = random_indices_per_class(test_labels, seed=seed)
    f, axarr = plt.subplots(4, len(idx_dict), figsize=(12, 4))
    for i, (c, idx) in tqdm(enumerate(idx_dict.items()), total=len(idx_dict)):
        # print(f"{i+1:02}/{len(class_names)}", end="\r")
        # Prepare input dict for network
        inp = {
            "parameters": conf["parameters"][idx : (idx + 1)],
            "summary_conditions": conf["summary_conditions"][idx : (idx + 1)],
        }

        # Obtain samples and clip to prior range, instead of rejecting
        if method == "cmpe":
            samples = trainer.amortizer.sample(inp, n_steps=cmpe_steps, n_samples=n_samples)
        else:
            samples = trainer.amortizer.sample(inp, n_samples=n_samples, step_size=fmpe_step_size)
        samples = np.clip(samples, a_min=-1.01, a_max=1.01)

        # Plot truth and blurred
        axarr[0,i].imshow((inp["parameters"].reshape(image_size,image_size,3)+1)/2)
        axarr[1,i].imshow((inp["summary_conditions"].reshape(image_size,image_size,3)+1)/2)
        axarr[2,i].imshow((samples.mean(0).reshape(image_size,image_size,3)+1)/2)
        axarr[3,i].imshow((samples.std(0).reshape(image_size,image_size,3)+1)/2)
        axarr[0, i].set_title(class_names[i])

    for j, label in enumerate(y_labels):
        axarr[j, 0].set_ylabel(label, rotation=0, labelpad=55, fontsize=12)

    # get rid of axis
    for ax in axarr.flat:
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)
        ax.spines["top"].set_visible(False)
        ax.spines["bottom"].set_visible(False)
        ax.set_yticklabels([])
        ax.set_yticks([])
        ax.set_xticklabels([])
        ax.set_xticks([])
    f.tight_layout()

    if filepath is not None:
        f.savefig(filepath, dpi=300, bbox_inches="tight")
    return f

# for key, trainer in trainer_dict.items():
#     print(key)
#     fig_dir = f"figures/{key}"
#     os.makedirs(fig_dir, exist_ok=True)
#     f = create_mean_std_plots(
#         trainer,
#         seed=42,
#         filepath=os.path.join(fig_dir, "main.pdf"),
#         method=Namespace(**arg_dict[key]).method,
#         cmpe_steps=cmpe_steps,
#         fmpe_step_size=fmpe_step_size,
#         image_size = img_size
#     )

"""## Per-Class Generation: Samples"""

def create_sample_plots(trainer, seed=42, filepath=None, cmpe_steps=30, fmpe_step_size=1 / 248, method="" , image_size=224):
    """Helper function for displaying Figure 7 in main paper.
    Default seed is the one and only 42!
    """

    idx_dict = random_indices_per_class(test_labels, seed=seed)
    n_samples = 5
    f, axarr = plt.subplots(len(idx_dict), 2 + n_samples, figsize=(8.27, 11.69))
    titles = [r"Param. $\theta$", r"Obs. $x$"] + n_samples * ["Sample"]
    for i, (c, idx) in tqdm(enumerate(idx_dict.items()), total=len(idx_dict)):
        # Prepare input dict for network
        print(conf["parameters"][idx : (idx + 1)].shape)
        inp = {
            "parameters": conf["parameters"][idx : (idx + 1)],
            "summary_conditions": conf["summary_conditions"][idx : (idx + 1)],
        }

        # Obtain samples and clip to prior range, instead of rejecting
        if args.type == "addim":
            samples = trainer.amortizer.sample_addim(inp, n_steps=cmpe_steps, n_samples=n_samples, c1=args.c1, c2=args.c2)
        else:
            samples = trainer.amortizer.sample(inp, n_steps=cmpe_steps, n_samples=n_samples)
        samples = np.clip(samples, a_min=-1.01, a_max=1.01)

        # Plot truth and blurred
        axarr[i,0].imshow((inp["parameters"].reshape(image_size,image_size,3)+1)/2)
        axarr[i,1].imshow((inp["summary_conditions"].reshape(image_size,image_size,3)+1)/2)
        axarr[i,2].imshow((samples.mean(0).reshape(image_size,image_size,3)+1)/2)
        for j in range(n_samples):
            axarr[i, 2 + j].imshow((samples[j].reshape(image_size,image_size,3)+1)/2)

        axarr[i, 0].set_ylabel(class_names[i], fontsize=12)

    for i, title in enumerate(titles):
        axarr[0, i].set_title(title, fontsize=12)

    # get rid of axis
    for ax in axarr.flat:
        ax.spines["right"].set_visible(False)
        ax.spines["left"].set_visible(False)
        ax.spines["top"].set_visible(False)
        ax.spines["bottom"].set_visible(False)
        ax.set_yticklabels([])
        ax.set_yticks([])
        ax.set_xticklabels([])
        ax.set_xticks([])
    f.tight_layout()

    if filepath is not None:
        f.savefig(filepath, dpi=300, bbox_inches="tight")
        pass
    return f

for key, trainer in trainer_dict.items():
    print(key)
    fig_dir = f"figures/{key}"
    os.makedirs(fig_dir, exist_ok=True)
    f = create_sample_plots(
        trainer,
        seed=42,
        filepath=os.path.join(fig_dir, "samples_main.pdf"),
        method=arg_dict[key].method,
        cmpe_steps=cmpe_steps,
        fmpe_step_size=fmpe_step_size,
        image_size = img_size
    )
    f.show()


##############################
### New Metrics
##############################

import torch
import torch.nn.functional as F
from skimage.metrics import peak_signal_noise_ratio, structural_similarity, mean_squared_error
from torchmetrics.image.kid import KernelInceptionDistance
import torchvision.transforms.functional as TF
import lpips
import numpy as np
import timeit
import random

# === SETING SEEDS ===
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)

# === CONFIG ===
batch_size = 64
n_samples = 1
n_datasets = num_test

# === DEVICE SETUP ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
torch.backends.cudnn.benchmark = True  # optimize conv performance

# === METRICS ===
lpips_metric = lpips.LPIPS(net='vgg').to(device)  # CHANGED to VGG + moved to GPU

# === INPUT PARAMS ===
parameters = conf["parameters"][:n_datasets]  # SHAPE: (n_datasets, 224*224*3)

def render_from_params(param_vector):
    img = param_vector.reshape(img_size, img_size, 3)
    return (img + 1.0) / 2.0  # scale to [0,1]

for key, trainer in trainer_dict.items():
    print(f"== Evaluating trainer: {key} ==")

    # Initialize KID per-trainer
    kid_metric = KernelInceptionDistance(subset_size=100).to(device)

    # Pre-initialize model
    if args.type == "addim":
        c = conf["summary_conditions"][0, None]
        with torch.no_grad():
            trainer.amortizer.sample_addim({"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples, c1=args.c1 , c2=args.c2)

    else:
        c = conf["summary_conditions"][0, None]
        with torch.no_grad():
            trainer.amortizer.sample({"summary_conditions": c}, n_steps=cmpe_steps, n_samples=n_samples)

    for theta in np.linspace(50, 250, 21):
        all_psnr, all_ssim, all_lpips, all_mses = [], [], [], []

        tic = timeit.default_timer()

        with torch.no_grad():
            for b_start in range(0, n_datasets, batch_size):
                b_end = min(b_start + batch_size, n_datasets)
                b_size = b_end - b_start

                batch_params = parameters[b_start:b_end]
                batch_conditions = conf["summary_conditions"][b_start:b_end]

                # === SAMPLE FROM MODEL ===
                if args.type == "addim":
                    batch_samples = []
                    for i in range(b_size):
                        sample = trainer.amortizer.sample_addim(
                            {"summary_conditions": batch_conditions[i, None]},
                            n_steps=cmpe_steps,
                            n_samples=n_samples,
                            c1=args.c1,
                            c2=args.c2
                        )
                        batch_samples.append(sample[0])
                    batch_samples = np.stack(batch_samples)  # shape: (b_size, D)
                else:
                    batch_samples = []
                    for i in range(b_size):
                        sample = trainer.amortizer.sample(
                            {"summary_conditions": batch_conditions[i, None]},
                            n_steps=cmpe_steps,
                            n_samples=n_samples
                        )
                        batch_samples.append(sample[0])
                    batch_samples = np.stack(batch_samples)  # shape: (b_size, D)

                # === RENDER & CONVERT TO GPU TENSORS ===
                true_imgs = np.stack([render_from_params(p) for p in batch_params])  # [B, 224, 224, 3]
                recon_imgs = np.stack([render_from_params(p) for p in batch_samples])  # [B, 224, 224, 3]

                true_tensors = torch.stack([TF.to_tensor(i) for i in true_imgs]).to(device)  # [B,3,224,224]
                recon_tensors = torch.stack([TF.to_tensor(i) for i in recon_imgs]).to(device)

                # === FOR KID (resize to 299x299 and convert to uint8) ===
                true_299 = F.interpolate((true_tensors * 255).clamp(0, 255),
                                         size=(299, 299), mode='bilinear', align_corners=False)
                recon_299 = F.interpolate((recon_tensors * 255).clamp(0, 255),
                                          size=(299, 299), mode='bilinear', align_corners=False)

                true_299 = true_299.to(torch.uint8)
                recon_299 = recon_299.to(torch.uint8)

                kid_metric.update(true_299, real=True)
                kid_metric.update(recon_299, real=False)

                # === FOR LPIPS (resize to 64x64, range [-1,1]) ===
                true_lpips = F.interpolate((true_tensors * 2 - 1), size=(64, 64), mode='bilinear', align_corners=False)
                recon_lpips = F.interpolate((recon_tensors * 2 - 1), size=(64, 64), mode='bilinear', align_corners=False)

                # === LPIPS computation ===
                lpips_vals = lpips_metric(true_lpips, recon_lpips).squeeze().cpu().numpy()  # [B]
                all_lpips.extend(lpips_vals.tolist())

                # === Other metrics (CPU, skimage) ===
                for i in range(b_size):
                    psnr = peak_signal_noise_ratio(true_imgs[i], recon_imgs[i], data_range=1.0)
                    ssim = structural_similarity(true_imgs[i], recon_imgs[i], channel_axis=-1, data_range=1.0)
                    mse = mean_squared_error(true_imgs[i], recon_imgs[i])
                    all_psnr.append(psnr)
                    all_ssim.append(ssim)
                    all_mses.append(mse)

        toc = timeit.default_timer()
        duration = toc - tic

        # === KID RESULT ===
        kid_mean, kid_std = kid_metric.compute()

        print(
            f"Theta: {theta:.3f} | "
            f"PSNR: {np.mean(all_psnr):.2f} dB | "
            f"SSIM: {np.mean(all_ssim):.3f} | "
            f"LPIPS: {np.mean(all_lpips):.3f} | "
            f"MSE: {np.mean(all_mses):.6f} | "
            f"KID: {kid_mean.item():.4f} ± {kid_std.item():.4f} | "
            f"Time: {duration:.2f}s"
        )
